% grundlagen.tex
In Kapitel~\ref{kapitel:grundlagen_kanalkodierung} werden Prinzipien und Eigenschaften der Kanalkodierung beschrieben. Kapitel~\ref{kapitel:grundlagen_faltungskodierung} geht auf Faltungskodes ein, eine Art der Kanalkodierung auf die sich diese Arbeit konzentriert. Der Inhalt dieser Kapitel orientiert sich an \cite{huffman2010fundamentals}, sowie \cite{morelos2006art} und~\cite{schonfeld2012informations}.
\section{Kanalkodierung}
\label{kapitel:grundlagen_kanalkodierung}
\begin{figure}[t]
\centering
\resizebox{\textwidth}{!}{%
	\input{tikz/kommunikationskanal}
}
\caption{Kommunikationskanal}
\label{abb:kommunikationskanal}
\end{figure}
Kanalkodierung kann als Zuordnung bzw. Abbildung von Quellzeichen zu Kanalzeichen angesehen werden. Quellzeichen sind Zeichen, die eine Informationsquelle emittiert. Kanalzeichen sind Zeichen, die über einen Kommunikationskanal übertragen werden. Der Kanal enthält ein Rauschen, d.h. Informationen die von der Quelle emittiert werden, können verändert beim Empfänger ankommen. Daher wird der Kanal als \emph{verrauschter} Kanal bezeichnet. Würde eine Information unkodiert über den verrauschten Kanal übertragen werden, könnte die verfälschte Nachricht nicht wiederhergestellt werden. Daher fügt ein Kanalkodierer den Quellzeichen Redundanz hinzu, sodass empfängerseitig verfälschte Zeichen erkannt und korrigiert werden können.

Abbildung~\ref{abb:kommunikationskanal} zeigt einen Kommunikationskanal. Eine Nachricht $\mathbf{u}=\left( u_{1},u_{2},\dots ,u_{k}\right)$ wird in ein Kodewort $\mathbf{v}=\left( v_{1},v_{2},\dots ,v_{n}\right)$, welches Redundanz enthält, kodiert. Vor der Übertragung über den Kanal werden die Bits folgendermaßen auf die Signalpegel +1 bzw. -1 abgebildet:
\begin{equation}
\text{Signal(Bit)} =
\begin{cases}
  +1  & \quad \text{wenn Bit} = 0\\
  -1  & \quad \text{wenn Bit} = 1\\
\end{cases}
\label{eq:bit_zu_signal_abbildung}
\end{equation}
Bei der Übertragung wird das Signal durch Rauschen, welches als Fehlervektor $\mathbf{e}=\left( e_{1},e_{2},\dots ,e_{n}\right)$ dargestellt wird, verfälscht. Der Empfangsvektor $\mathbf{y}$ ergibt sich aus der Überlagerung von $\mathbf{v}$ und $\mathbf{e}$. Der Empfangsvektor wird vor der Dekodierung von den Signalpegeln zurück auf die Bit-Werte 0 bzw. 1 abgebildet.
\begin{equation}
\text{Kode(Signal)} =
\begin{cases}
  0  & \quad \text{wenn Signal } \geq 0\\
  1  & \quad \text{sonst}\\
\end{cases}
\label{eq:signal_zu_bit_abbildung}
\end{equation}
Das daraus resultierende Kodewort wird vom Dekodierer zur Schätzung $\mathbf{u'}$ der originalen Nachricht dekodiert. Ziel der Kanalkodierung ist, dass die Wahrscheinlichkeit von $\mathbf{u'}=\mathbf{u}$ maximiert wird.

\subsection{Koderate}
\label{kapitel:grundlagen_koderate}
Die Koderate $R$ eines Kodes beschreibt das Verhältnis der Länge zwischen dem Quellwort $\mathbf{u}=\left( u_{1},u_{2},\dots ,u_{k}\right)$ und dem Kodewort $\mathbf{v}=\left( v_{1},v_{2},\dots ,v_{n}\right)$.
\begin{equation}
R=\frac{k}{n}<1
\end{equation}
Wobei $k$ bzw. $n$ den Längen des Quellworts bzw. Kodeworts entsprechen. Somit beschreibt die Koderate das Verhältnis zwischen Information und Redundanz im übertragenen Kodewort. Bei hoher Redundanz ergibt sich eine niedrige Koderate. Die Übertragung ein und derselben Information bei gleicher Übertragungsgeschwindigkeit dauert bei Kodes mit niedriger Koderate länger, als bei Kodes mit höherer Koderate.
\pagebreak
\subsection{Hamming-Distanz}
\label{kapitel:grundlagen_hamming_distanz}
Die Hamming-Distanz $d$ (auch $d_{H}$) zweier Kodewörter $\mathbf{a}=\left( a_{1},a_{2},\dots ,a_{n}\right)$ und $\mathbf{b}=\left( b_{1},b_{2},\dots ,b_{n}\right)$ entspricht der Anzahl an Stellen, in denen sich die beiden Kodewörter unterscheiden:
\begin{equation}
d(a,b)=\vert\left\lbrace i \in \left\lbrace 1,2,\dots ,n \right\rbrace\vert a_{i}\neq b_{i}\right\rbrace\vert\; .
\end{equation}
Für binäre Kodewörter ergibt sich die Hamming-Distanz aus der binären Addition der Kodewörter:
\begin{equation}
d(a,b)=\sum_{i=1}^{n} \left( a_{i} \oplus b_{i}\right).
\end{equation}
Das Hamming-Gewicht $w$ eines binären Kodeworts $\mathbf{a}=\left( a_{1},a_{2},\dots ,a_{n}\right)$ entspricht der Anzahl an Bits im Wort, für die gilt $a_{i}=1$ mit $i \in \left\lbrace 1,2,\dots ,n \right\rbrace$.
\begin{equation}
w(a)=\vert\left\lbrace i \in \left\lbrace 1,2,\dots ,n \right\rbrace\vert a_{i}=1\right\rbrace\vert=\sum_{i=1}^{n} a_{i}
\end{equation}

\section{Faltungskodierung}
\label{kapitel:grundlagen_faltungskodierung}
Faltungskodes sind blockfreie Kodes, d.h. Quellzeichen werden nicht in Blöcke fester Länge unterteilt, vielmehr wird ein Informationsstrom kodiert, sodass ein einziges Kodewort resultiert. Ein weiterer Unterschied zu Blockkodes besteht darin, dass Kodebits nicht nur vom aktuellen Eingangsbit abhängen, sondern auch von vorherigen Eingangsbits. Die Redundanz wird bei Faltungskodes kontinuierlich in das Kodewort eingefügt. Im Allgemeinen können Faltungskodierer beliebig viele Eingänge haben, sodass mehrere Informationsbits gleichzeitig kodiert werden. Trotz besserer Koderate bei Kodierern mit mehreren Eingängen sind nur Kodierer mit einem Eingang von praktischer Relevanz. Im Folgenden werden nur noch Faltungskodierer mit einem Eingang betrachtet.

\subsection{Kodiererdarstellung und Kodierung}
\label{kapitel:grundlagen_darstellung}
Faltungskodierer lassen sich einfach durch ein Schieberegister und mehrere logische XOR-Gatter darstellen. Bei einem Faltungskodierer mit $N$ Ausgängen und einem Schieberegister der Länge $M$ wird ein Eingangsbit $u \in \left\lbrace 0,1 \right\rbrace$ in eine Kodesequenz $\mathbf{v}$ der Länge $N$ $\left( \mathbf{v} \in {\left\lbrace 0,1\right\rbrace }^{N}\right)$ kodiert. Es ergibt sich somit eine Koderate von $R=\frac{1}{N}$. Ein Ausgang wird durch ein sogenanntes \emph{Generatorpolynom} definiert. Ein Generatorpolynom stellt eine Linearkombination der $M$ Elemente des Schieberegisters und dem Eingangssignal dar und wird durch ein XOR-Gatter abgebildet. Alle Generatorpolynome werden in einer \emph{Generatormatrix}
\begin{equation}
G=\left( g_{1}, g_{2},\dots , g_{N} \right) 
\end{equation}
angegeben, wobei das Generatorpolynom $g_{i}$ den Ausgang $i$ definiert. Zur Definition eines Faltungskodierers im praktischen Teil der Arbeit müssen die Generatorpolynome angegeben werden.
\\
Ein weiterer wichtiger Parameter von Faltungskodes ist die \emph{Einflusslänge} (constraint length). Diese gibt an, wie oft sich ein Eingangsbit auf die Kodierung auswirkt. Die Einflusslänge wird durch die Länge des Schieberegisters bestimmt. Ein Eingangsbit beeinflusst $M+1$ mal die Kodierung.
\\
\\
Die Verhaltensweise eines Faltungskodierers kann durch seinen \emph{Zustandsgraphen} beschrieben werden. Ein Zustand entspricht einer bestimmten Bitbelegung des Schieberegisters. Für einen Faltungskodierer mit einem Schieberegister der Länge $M$ ergeben sich $2^{M}$ Zustände. Faltungskodierer starten, falls nicht explizit angegeben, im Nullzustand, d.h. die Elemente des Schieberegisters sind mit 0 initialisiert.
\begin{figure}[t]
	\centering
	\begin{subfigure}{0.65\textwidth}
		\centering
		\resizebox{0.99\textwidth}{!}{%
			\input{tikz/standardkodierer}
		}
		\caption{Schaltbild}
		\label{abb:bsp1_schaltbild}
	\end{subfigure}
	~ % spacing between subfigures
	\begin{subfigure}{0.3\textwidth}
		\centering
		\resizebox{0.99\textwidth}{!}{%
			\input{tikz/zustandsdiagramm}
		}
		\caption{Zustandsdiagramm}
		\label{abb:bsp1_zustandsdiagramm}
	\end{subfigure}
	\caption{Beispiel für Faltungskodierer}
	\label{abb:standardkodierer}
\end{figure}
\begin{beispiel} Ein Faltungskodierer ist gegeben durch das Schaltbild bzw. Zustandsdiagramm in Abbildung~\ref{abb:standardkodierer}. Der Faltungskodierer besitzt die Generatormatrix 
\begin{equation*}
G=\left(7_{8},5_{8}\right) = \begin{pmatrix}
111 \\
101 \\
\end{pmatrix} = \left(1+D+D^{2}, 1+D^{2} \right)
\end{equation*}
\label{bsp:B1}
\end{beispiel}
Beispiel~\ref{bsp:B1} zeigt die verschiedenen Notationen für die Generatormatrix. Die am häufigsten verwendete Schreibweise ist die Darstellung der Generatorpolynome in oktaler Form. Dabei werden die Polynome in binärer Schreibweise konzise zu oktalen Zahlen zusammengefasst. Bei der binären Schreibweise entspricht die Bitposition des Polynoms dem Element im Schaltbild, d.h. das Most Significant Bit (MSB) des Polynoms steht für das Eingangssignal, das Least Significant Bit (LSB) des Polynoms steht für den Inhalt des letzten (am weitesten rechts liegenden) Elements des Schieberegisters. In die Linearkombination zur Definition des Ausgangssignals werden jene Elemente miteinbezogen, an deren Stelle im binären Polynom eine 1 steht. In \cite{huffman2010fundamentals} wird die Notation der binären Polynome über der Variable $D$ (\enquote{delay}) eingeführt. Das Eingangssignal und die Schieberegisterelemente entsprechen einer Potenz von $D$, wobei das Eingangssignal $u$ der Potenz $D^{0}=1$ und das letzte Schieberegisterelement $D^{M}$ entspricht. Das Generatorpolynom ergibt sich aus der Summe aller Potenzen deren Elemente Teil der Linearkombination sind. Darüber hinaus wird in Abbildung~\ref{abb:bsp1_zustandsdiagramm} das Zustandsdiagramm abgebildet. Die Knoten stellen die Zustände des Kodierer, d.h. die Belegungen des Schieberegisters, dar. Die gerichteten Kanten entsprechen einem Übergang bei einem Eingangsbit, wobei eine durchgezogene Kante einer 0 als Eingangsbit entspricht und eine gestrichelte Kante einer 1. Die Kantenbewertungen entsprechen den Ausgangsbits.

\begin{beispiel} Gegeben sei der Faltungskodierer aus Beispiel~\ref{bsp:B1}. Eine Nachricht $\mathbf{u}=\left( 110100\right)$ wird in den Kode $\mathbf{v}=\left( 11~01~01~00~10~11\right)$ kodiert.
\label{bsp:B2}
\end{beispiel}

\subsection{Dekodierung}
\label{kapitel:grundlagen_dekodierung}
\begin{figure}[t]
	\centering
	%\resizebox{\textwidth}{!}{%
		\input{tikz/trellis_kodierung}
	%}
\caption{Trellis für die Kodierung zu Beispiel~\ref{bsp:B2}}
\label{abb:trellis_kodierung}
\end{figure}
Zur Dekodierung von Faltungskodes wird der \emph{Viterbi-Algorithmus} angewendet. Der Algorithmus verwendet zur Dekodierung einer Kodesequenz das \emph{Trellis-Diagramm} (kurz: Trellis). Abbildung~\ref{abb:trellis_kodierung} zeigt das Trellis zur Kodierung der Nachricht aus Beispiel~\ref{bsp:B2}. Das Trellis ist eine Erweiterung des Zustandsdiagramms um eine Zeitachse auf der Abszisse. Die Zustände sind auf der Ordinate aufgetragen. Das Diagramm startet, wie die Kodierung, im Nullzustand. Ein durchgezogener Pfeil entspricht einer 1 als Eingangsbit, ein gestrichelter Pfeil einer 0 als Eingangsbit. Die Pfeile sind wiederum mit den entsprechenden Ausgangsbits, die das Kodewort ergeben, bewertet.

Der Viterbi-Algorithmus verwendet das Trellis zur Dekodierung eines empfangenen Kodes. Dabei wird für den empfangenen Kode im Trellis jener Pfad gesucht, der eine bestimmte Metrik minimiert bzw. maximiert. Die Metrik hängt von der Art der Dekodierung ab. Es wird zwischen der \emph{hard~decision} Dekodierung und \emph{soft~decision} Dekodierung unterschieden.

\subsubsection{hard decision}
\label{kapitel:grundlagen_hard_decision}
Die hard decision Dekodierung sucht den Pfad mit der geringsten Anzahl an Bitfehlern im Trellis. Der Algorithmus startet im Nullzustand und durchläuft das Trellis von links nach rechts, wobei die Metriken der Kanten berechnet werden. Für eine Kante, die einen Zustand $s$ zum Zeitpunkt $t$ mit einem Zustand $s'$ zum Zeitpunkt $t+1$ verbindet, ist die Metrik die Hamming-Distanz zwischen der Bewertung der Kante, die $s$ und $s'$ verbindet, und dem zum Zeitpunkt $t$ empfangenen Teil des Kodes. Die Metrik eines Pfads im Trellis ist die Summe der Kantenmetriken des Pfads. Ein Pfad mit einer großen Metrik hat eine große Hamming-Distanz zum empfangenen Kode, daher wird der Pfad mit der minimalen Metrik gesucht. Zu jedem Zeitpunkt wird in allen Zuständen die Pfadmetrik zu diesem Zustand berechnet. Treffen zwei Pfade aufeinander, wird der Pfad mit der größeren Hamming-Distanz verworfen.
\\
Am Ende erhält man durch \emph{Backtracking} die dekodierte Nachricht. Beginnend bei der niedrigsten Metrik am Ende des Trellis, wird der Pfad zum Nullzustand rückwärts durchlaufen. Als Ergebnis resultiert die Nachricht, dessen Kode die geringste Hamming-Distanz zum empfangenen Kode hat.
\begin{beispiel}
Gegeben sei der Faltungskodierer aus Beispiel~\ref{bsp:B1} und ein empfangenes Kodewort $\mathbf{y}=\left( 11~00~01~01~10~11\right)$ welches durch Rauschen verfälscht wurde und dekodiert werden soll. Abbildung~\ref{abb:trellis_dek_hard_a} zeigt die Dekodierung im Trellis mit den Metriken aller Pfade. Die verworfenen Pfade sind grau dargestellt. Beispielsweise ergibt sich die Metrik zum Zeitpunkt 1 im Zustand 00 durch $0+d(00,11)=2$, im Zustand 10 durch $0+d(11,11)=0$. Der erste Summand entspricht der Hamming-Distanz des vorigen Zustands. In Abbildung~ \ref{abb:trellis_dek_hard_b} werden die verworfenen Pfade nicht mehr angezeigt. Durch Backtracking erhält man die dekodierte Nachricht $\mathbf{u'}=\left( 110100\right)$. Der resultierende Pfad ist orange hervorgehoben. Man erkennt aus der Metrik am Ende der Trellis, dass der empfangene Kode zwei Bitfehler enthielt.
\label{bsp:B3}
\end{beispiel}

\begin{figure}[t]
	\centering
	\resizebox{0.70\textwidth}{!}{%
		\input{tikz/trellis_dekodierung_hard1}
	}
	\caption{Vollständiges Trellis der hard decision Dekodierung zu Beispiel~\ref{bsp:B3}}
	\label{abb:trellis_dek_hard_a}
\end{figure}
\begin{figure}[t]
	\centering
	\resizebox{0.70\textwidth}{!}{%
		\input{tikz/trellis_dekodierung_hard2}
	}
	\caption{Backtracking im Trellis der hard decision Dekodierung zu Beispiel~\ref{bsp:B3}}
	\label{abb:trellis_dek_hard_b}
\end{figure}

%\begin{figure}[t]
%	\centering
%	\resizebox{\textwidth}{!}{%
%		\begin{subfigure}[t]{0.42\textwidth}
%			\centering
%			\resizebox{0.99\textwidth}{!}{%
%				\input{tikz/trellis_dekodierung_hard1}
%			}
%			\caption{}
%			\label{abb:trellis_dek_hard_a}
%		\end{subfigure}
%		\begin{subfigure}[t]{0.42\textwidth}
%			\centering
%			\resizebox{0.99\textwidth}{!}{%
%				\input{tikz/trellis_dekodierung_hard2}
%			}
%			\caption{}
%			\label{abb:trellis_dek_hard_b}
%		\end{subfigure}
%	}
%	\caption{Trellis der hard decision Dekodierung zu Beispiel~\ref{bsp:B3}}
%	\label{abb:trellis_dekodierung_hard}
%\end{figure}

\subsubsection{soft decision}
\label{kapitel:grundlagen_soft_decision}
Vor der Übertragung eines Kodeworts werden die Kodebits 0 bzw. 1 nach Gleichung~\eqref{eq:bit_zu_signal_abbildung} auf die Signalzustände +1 bzw. -1 abgebildet. Bei der hard decision Dekodierung muss vor der Dekodierung das Signal nach Gleichung~\eqref{eq:signal_zu_bit_abbildung} wieder zu einem Bitvektor zurück umgewandelt werden. Die soft decision Dekodierung lässt diese Rücktransformation aus und verwendet die exakten Signalpegel. Dadurch erzielt die soft decision Dekodierung eine noch bessere Fehlerkorrektur. Die Metrik für eine Kante, die einen Zustand $s$ zum Zeitpunkt $t$ mit einem Zustand $s'$ zum Zeitpunkt $t+1$ verbindet, entspricht dem Skalarprodukt der Signalzustände der Bewertung der Kante zwischen $s$ und $s'$ und dem zum Zeitpunkt $t$ empfangenen Teil des Signals. Der Viterbi-Algorithmus funktioniert analog zur soft decision Dekodierung, jedoch wird der Pfad mit der maximalen Metrik gesucht. Treffen zwei Pfade aufeinander, wird der Pfad mit der kleineren Metrik verworfen. Das Backtracking beginnt hier bei der größten Metrik. Als Ergebnis resultiert die Nachricht, dessen Signal das größte Skalarprodukt mit dem empfangenen Signal hat.
\\
\\
Die Nachricht wird mittels \emph{Soft-Werten} und \emph{Hard-Werten} angegeben. Die Soft-Werte geben neben der dekodierten Nachricht die Zuverlässigkeitswerte für die Bits an, d.h. mit welcher Wahrscheinlichkeit das Bit mit dem tatsächlich gesendeten Bit der Quellnachricht übereinstimmt. Positive Soft-Werte werden auf eine 0, negative auf eine 1 abgebildet. Der Betrag des Soft-Werts gibt die Zuverlässigkeit an, wobei gilt, je höher der Betrag, desto zuverlässiger das dekodierte Bit. Die Hard-Werte entsprechen der Abbildung der Soft-Werte auf die Bit-Werte 0 bzw. 1. Der Viterbi-Algorithmus mit Soft-Werten wird auch SOVA (Soft Output Viterbi Algorithm) genannt. Die Berechnung der Soft-Werte ist in \cite[S.~228~ff.]{schonfeld2012informations} beschrieben.

\begin{beispiel}
Gegeben sei der Faltungskodierer aus Beispiel~\ref{bsp:B1} und ein empfangenes Signal $\mathbf{y}=\left( -1~-1~~0.5~-1~~0.9~-0.9~~1~-0.2~~-0.8~-0.1~-1~-1\right)$, welches durch Rauschen verfälscht wurde und dekodiert werden soll. Abbildung~\ref{abb:trellis_dek_soft_a} zeigt die Dekodierung im Trellis mit den Metriken aller Pfade. Die verworfenen Pfade sind grau dargestellt. Beispielsweise ergibt sich die Metrik zum Zeitpunkt 1 im Zustand 00 durch $0+\left( 1\cdot\left( -1\right) + 1\cdot\left( -1\right)\right) =0-2=-2$, im Zustand 10 durch $0+\left( \left( -1\right)\cdot\left( -1\right) + \left( -1\right)\cdot\left( -1\right)\right) =0+2=2$. Der erste Summand entspricht der Metrik des vorigen Zustands. Die Bits der Kantenbewertung im Trellis müssen für die Berechnung des Skalarprodukts auf die Signalzustände +1 bzw. -1 abgebildet werden. In Abbildung~\ref{abb:trellis_dek_soft_b} werden die verworfenen Pfade nicht mehr angezeigt. Aus dem Backtracking resultiert die dekodierte Nachricht $\mathbf{u'}=\left( 110100\right)$. Der Pfad der dekodierten Nachricht im Trellis ist orange hervorgehoben.
\label{bsp:B4}
\end{beispiel}

\begin{figure}[t]
	\centering
	\resizebox{0.70\textwidth}{!}{%
		\input{tikz/trellis_dekodierung_soft1}
	}
	\caption{Vollständiges Trellis der soft decision Dekodierung zu Beispiel~\ref{bsp:B4}}
	\label{abb:trellis_dek_soft_a}
\end{figure}
\begin{figure}[t]
	\centering
	\resizebox{0.70\textwidth}{!}{%
		\input{tikz/trellis_dekodierung_soft2}
	}
	\caption{Backtracking im Trellis der hard decision Dekodierung zu Beispiel~\ref{bsp:B4}}
	\label{abb:trellis_dek_soft_b}
\end{figure}

%\begin{figure}[t]
%	\centering
%	\resizebox{\textwidth}{!}{%
%		\begin{subfigure}[t]{0.42\textwidth}
%			\centering
%			\resizebox{0.99\textwidth}{!}{%
%				\input{tikz/trellis_dekodierung_soft1}
%			}
%			\caption{}
%			\label{abb:trellis_dek_soft_a}
%		\end{subfigure}
%		\begin{subfigure}[t]{0.42\textwidth}
%			\centering
%			\resizebox{0.99\textwidth}{!}{%
%				\input{tikz/trellis_dekodierung_soft2}
%			}
%			\caption{}
%			\label{abb:trellis_dek_soft_b}
%		\end{subfigure}
%	}
%	\caption{Trellis der soft decision Dekodierung zu Beispiel~\ref{bsp:B4}}
%	\label{abb:trellis_dekodierung_soft}
%\end{figure}

\subsection{Katastrophale Faltungskodierer}
\label{kapitel:grundlagen_katastrophale_kodierer}
Sei $\mathbf{u}$ eine Nachricht, die mit den Generatorpolynomen in $G$ zum Kode $\mathbf{v}$ kodiert wird. Nach der Übertragung erhält der Dekodierer den Kode $\mathbf{y}$, der aufgrund von Rauschen verändert sein könnte. Der Dekodierer findet ein Kodewort $\mathbf{v'}$ welches $\mathbf{v}$ am nächsten ist. Aus $\mathbf{v'}$ kann die Schätzung $\mathbf{u'}$, die möglichst $\mathbf{u}$ entsprechen sollte, berechnet werden. Dies ist bei einer fehlerfreien Übertragung, d.h. $\mathbf{v'}=\mathbf{v}$, sicherlich der Fall. Im Folgenden wird der Fall $\mathbf{v'}\neq\mathbf{v}$ untersucht: Zu erwarten wäre, wenn sich $\mathbf{v'}$ und $\mathbf{v}$ in endlich vielen Stellen unterscheiden, dass sich auch $\mathbf{u'}$ und $\mathbf{u}$ in endlich vielen Stellen unterscheiden. Wenn sich $\mathbf{u'}$ und $\mathbf{u}$ in unendlich vielen Stellen unterscheiden, wäre das \emph{katastrophal}. Ein Faltungskodierer wird katastrophal genannt, wenn es eine Nachricht mit unendlichem Hamming-Gewicht gibt, sodass sein Kode endliches Hamming-Gewicht hat. Katastrophale Kodierer sind zu vermeiden, da eine endliche Anzahl an Übertragungsfehler zu einer unendlichen Anzahl an Dekodierfehler führen kann.~\cite[S.~569]{huffman2010fundamentals}
\\
\\
Zur Überprüfung, ob ein Kodierer katastrophal ist, hilft das Theorem von Massey-Sain~\cite[S.~570]{huffman2010fundamentals}. Sei ein Faltungskodierer mit einem Eingang und der Generatormatrix $G$ als Polynome über $D$ gegeben. Der Kodierer ist nicht katastrophal genau dann, wenn der größte gemeinsame Teiler der Generatorpolynome eine Potenz von $D$ ist.
\begin{figure}[t]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\resizebox{0.90\textwidth}{!}{%
			\input{tikz/systematischer_kodierer}
		}
		\caption{Systematischer Faltungskodierer}
		\label{abb:systematischer_kodierer}
	\end{subfigure}
	~ % spacing between subfigures
	\begin{subfigure}{0.45\textwidth}
		\centering
		\resizebox{0.99\textwidth}{!}{%
			\input{tikz/rsc}
		}
		\caption{Rekursiv Systematischer Faltungskodierer}
		\label{abb:rsc_kodierer}
	\end{subfigure}
\caption{Verschiedene Faltungskodierertypen}
\label{abb:faltungskodierer_typen}
\end{figure}

\subsection{Systematische Faltungskodierer}
\label{kapitel:grundlagen_systematische_kodierer}
Bei systematischen Faltungskodierern entspricht ein Ausgang dem Eingangssignal. Die Quellinformation ist somit explizit im Kodewort enthalten. Abbildung \ref{abb:systematischer_kodierer} zeigt einen systematischen Faltungskodierer mit der Generatormatrix $G=\left( 4_{8},7_{8}\right)$. Systematische Faltungskodierer sind nie katastrophal, sie sind jedoch weniger robust wie nichtsystematische Faltungskodierer.~\cite[S.~217]{schonfeld2012informations}

\subsection{Rekursiv systematische Faltungskodierer}
\label{kapitel:grundlagen_rsc}
Rekursiv systematische Faltungskodierer (RSC-Kodierer\footnote{Recursive Systematic Convolutional Coder}) weisen sowohl einen systematischen Ausgang, als auch eine Rückkopplung des Schieberegisters zum Eingang vor. Aus Letzterem ergibt sich eine unendliche Einflusslänge. Das Eingangssignal ist, wie bei allen systematischen Kodierern, explizit im Kodewort enthalten. RSC-Kodierer sind aufgrund ihrer Verwendung in Turbo-Kodes von großer Bedeutung.
\\
Die Generatormatrix eines RSC-Kodierers mit einem Eingang wird folgendermaßen angegeben:
\begin{equation}
G=\left( 1, \frac{g_{1}}{g_{0}},\dots , \frac{g_{N-1}}{g_{0}} \right)
\end{equation}
Zumeist befindet sich an erster Stelle eine 1, welche den systematischen Ausgang notiert. Das Polynom $g_{0}$ definiert die Rückkopplung des Kodierers. Die Polynome $g_{1}$ bis $g_{N-1}$ stellen die Polynome der nichtsystematischen Ausgänge dar~\cite[S.~92~f.]{morelos2006art}.

Zur Definition eines RSC-Kodierers im praktischen Teil der Arbeit müssen die oktalen Generatorpolynome der nichtsystematischen Ausgänge sowie der Rekursion angegeben werden. Das Polynom des systematischen Ausgangs muss nicht angegeben werden. Abbildung \ref{abb:rsc_kodierer} zeigt einen rekursiv systematischen Faltungskodierer für die Generatormatrix $G=\left( 1,\frac{5_{8}}{7_{8}}\right)$.

\subsection{Terminierung}
\label{kapitel:grundlageen_terminierung}
Die Terminierung bezeichnet das Zurückkehren des Kodierers, nach der vollständigen Kodierung einer Nachricht, in den Nullzustand. Dazu wird das Schieberegister mit $M$ 0-Bits befüllt. Die Terminierung wirkt sich positiv auf die Fehlerkorrekturfähigkeit bei der Dekodierung aus, da der Endzustand im Trellis immer der Nullzustand ist und somit bekannt ist. Jedoch geschieht dies auf Kosten der Koderate $R$, die durch die Terminierung sinkt. Die Koderate des terminierten Kodes $R_{t}$ berechnet sich für eine nicht terminierte Nachricht $\mathbf{u}=\left( u_{1},u_{2},\dots ,u_{k}\right)$ wie folgt:
\begin{equation}
R_{t}=\frac{k}{M+k}R
\end{equation}
Für lange Nachrichten ist $R_{t}\approx R$ und kann daher vernachlässigt werden.
\begin{figure}[t]
\input{tikz/trellis_terminiert}
\caption{Trellis für die terminierte Kodierung zu Beispiel~\ref{bsp:B5}}
\label{abb:trellis_terminiert}
\end{figure}
\begin{beispiel}
Gegeben sei die Nachricht $\mathbf{u}=\left( 110100\right)$ aus Beispiel~\ref{bsp:B2}. Die Kodierung der terminierten Nachricht ist in Abbildung~\ref{abb:trellis_terminiert} zu sehen und ergibt das Kodewort $\mathbf{v}=\left( 11~01~01~00~10~11~00~00\right)$.
\label{bsp:B5}
\end{beispiel}

\subsection{Punktierung}
\label{kapitel:grundlagen_punktierung}
Zur Erhöhung der Koderate $R$ eines Kodes gibt es die Möglichkeit der Punktierung. Dabei werden bestimmte Bits vor der Übertragung anhand der sogenannten \emph{Punktierungsmatrix} $P \in {\left\lbrace 0,1 \right\rbrace}^{N\times \frac{p}{N}}$ gestrichen, wobei $p$ als Periode der Punktierungsmatrix bezeichnet und $P$ spaltenweise durchlaufen wird. Das Gewicht der Matrix $w(P)$ entspricht der Anzahl nicht punktierter Kodebits je Periode, d.h. der Anzahl an Bits für die gilt $P_{ij}=1$ mit $i \in \left\lbrace 1,2,\dots ,N \right\rbrace$ und $j \in \left\lbrace 1,2,\dots ,\frac{p}{N} \right\rbrace$.~\cite[S.~218]{schonfeld2012informations}
\\
\\
Die Koderate des punktierten Kodes $R_{p}$ berechnet sich wie folgt:
\begin{equation}
R_{p}=\frac{p}{w(P)}R
\end{equation}
Vor der Dekodierung erfolgt die Depunktierung, d.h. die punktierten Kodebits werden wieder eingefügt. Bei der soft decision Dekodierung wird der Signalwert 0, also genau zwischen den eigentlichen Signalwerten +1 und -1, an den zuvor punktierten Stellen eingefügt. Bei der hard decision Dekodierung wird das Bit 0 eingefügt.

\begin{beispiel}
Gegeben sei das Kodewort $\mathbf{v}=\left( 11~01~01~00~10~11\right)$ aus Beispiel~\ref{bsp:B2} und die Punktierungsmatrix
\begin{equation*}
P=
\begin{pmatrix}
1 & 0 & 1 \\
1 & 1 & 0 \\
\end{pmatrix}.
\end{equation*}
Nach der Punktierung ergibt sich das Kodewort $\mathbf{v_{p}}=\left( 11\ast 10\ast 00\ast 01\ast\right) = \left( 11100001\right)$. Die Koderate des punktierten Kodes beträgt $R_{p}=\frac{6}{4}\cdot\frac{1}{2}=\frac{3}{4}$.
\label{bsp:B6}
\end{beispiel}